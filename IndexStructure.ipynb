{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "from heapq import heappop, heappush, heapify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Posting:\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        self.total_tf = 0  # Total frequency in all documents\n",
    "        self.total_df = 0  # Total number of documents containing the word\n",
    "        self.doc_tf = dict()  # Term frequency per document\n",
    "        self.positions = dict()  # Positional index\n",
    "        self.champion_list = None  # Champion list (another PostingList)\n",
    "\n",
    "    def add(self, doc_id, position):\n",
    "        self.total_tf += 1\n",
    "        if self.doc_tf.get(doc_id) is None:\n",
    "            self.doc_tf[doc_id] = 0\n",
    "            self.total_df += 1\n",
    "            self.positions[doc_id] = []\n",
    "        self.doc_tf[doc_id] += 1\n",
    "        self.positions[doc_id].append(position)\n",
    "\n",
    "    def tf(self, doc_id):\n",
    "        if self.doc_tf.get(doc_id) is None:\n",
    "            return 0\n",
    "        freq = self.doc_tf[doc_id]\n",
    "        return 1 + log(freq, 10)  # Logarithmic TF\n",
    "\n",
    "    def idf(self, N):\n",
    "        if self.total_df == 0:\n",
    "            return 0\n",
    "        return log(N / self.total_df, 10)  # Inverse Document Frequency\n",
    "\n",
    "    def get_list_of_docs(self):\n",
    "        return list(self.positions.keys())\n",
    "\n",
    "    def create_champion_list(self, size, N):\n",
    "        heap = []\n",
    "        heapify(heap)\n",
    "\n",
    "        # Calculate scores and maintain a heap of top `size` documents\n",
    "        for doc_id in self.positions.keys():\n",
    "            score = self.tf(doc_id) * self.idf(N) \n",
    "            heappush(heap, (score, doc_id))\n",
    "            if len(heap) > size:\n",
    "                heappop(heap)\n",
    "\n",
    "        # Extract the top documents and sort by doc_id\n",
    "        top_docs = []\n",
    "        while len(heap):\n",
    "            score, doc_id = heappop(heap)\n",
    "            top_docs.append((doc_id, score))\n",
    "\n",
    "        # Sort by doc_id (ascending order)\n",
    "        top_docs.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Create a new Posting object for the champion list\n",
    "        champion_posting_list = Posting(self.word)\n",
    "\n",
    "        # Add the sorted documents and their positions to the champion list\n",
    "        for doc_id, _ in top_docs:\n",
    "            for position in self.positions[doc_id]:\n",
    "                champion_posting_list.add(doc_id, position)\n",
    "\n",
    "        self.champion_list = champion_posting_list\n",
    "        return self.champion_list\n",
    "\n",
    "\n",
    "    def getfreq(self):\n",
    "        return self.doc_tf\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"total_tf={self.total_tf}, total_df={self.total_df}, word = {self.word}\\n\"\n",
    "            f\"doc_tf={self.doc_tf}, positions={self.positions}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tf=7, total_df=3, word = کلمه\n",
      "doc_tf={1: 2, 2: 2, 3: 3}, positions={1: [2, 5], 2: [3, 7], 3: [1, 4, 5]}\n",
      "\n",
      "total_tf=5, total_df=2, word = کلمه\n",
      "doc_tf={2: 2, 3: 3}, positions={2: [3, 7], 3: [1, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "posting_list = Posting(\"کلمه\")\n",
    "posting_list.add(1, 2)\n",
    "posting_list.add(1, 5)\n",
    "posting_list.add(2, 3)\n",
    "posting_list.add(2, 7)\n",
    "posting_list.add(3, 1)\n",
    "posting_list.add(3, 4)\n",
    "posting_list.add(3, 5)\n",
    "\n",
    "champion_list = posting_list.create_champion_list(size=2, N=N)\n",
    "print(posting_list)\n",
    "print(\"\")\n",
    "print(champion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostingsList:\n",
    "    def __init__(self):\n",
    "        self.dic_size = 0\n",
    "        self.norm_weight = dict() #for each doc\n",
    "        self.map = dict()  # (word,posting)\n",
    "        self.doc = dict()  # (doc(word,freq))\n",
    "        \n",
    "        self.champion_lists = dict()\n",
    "        self.freq_with_word = []\n",
    "\n",
    "\n",
    "    def add(self, word, doc_id, position):\n",
    "        if word not in self.map:\n",
    "            posting = Posting(word)\n",
    "            self.dic_size += 1\n",
    "            self.map[word] = posting\n",
    "\n",
    "        if doc_id not in self.doc:\n",
    "            self.doc[doc_id] = dict()\n",
    "\n",
    "        if word not in self.doc[doc_id]:\n",
    "            self.doc[doc_id][word] = 0\n",
    "\n",
    "        self.doc[doc_id][word] += 1\n",
    "        self.map[word].add(doc_id, position)\n",
    "\n",
    "    def tf(self, doc_id, word):\n",
    "        if word not in self.map:\n",
    "            return 0\n",
    "        return self.map[word].tf(doc_id)\n",
    "\n",
    "    def idf(self, word, N):\n",
    "        if word not in self.map:\n",
    "            return 0\n",
    "        return self.map[word].idf(N)\n",
    "\n",
    "    def score(self, doc_id, word, N):\n",
    "        return self.tf(doc_id, word) * self.idf(word, N)\n",
    "\n",
    "    def calcute_norm_weight(self):\n",
    "        for doc_id, word_freqs in self.doc.items():\n",
    "            norm_vector = {}\n",
    "            squared_sum = 0\n",
    "            for word, freq in word_freqs.items():\n",
    "                tf_idf_score = self.tf(doc_id, word) * self.idf(word, N)\n",
    "                norm_vector[word] = tf_idf_score\n",
    "                squared_sum += tf_idf_score ** 2\n",
    "\n",
    "            # Normalize weights\n",
    "            normalization_factor = sqrt(squared_sum)\n",
    "            if normalization_factor > 0:\n",
    "                for word in norm_vector:\n",
    "                    norm_vector[word] /= normalization_factor\n",
    "\n",
    "            self.norm_weight[doc_id] = norm_vector\n",
    "\n",
    "    def get_weight(self, doc_id, word):\n",
    "        if word not in self.norm_weight.get(doc_id, {}):\n",
    "            return 0\n",
    "        return self.norm_weight[doc_id][word]\n",
    "\n",
    "    def get_list_word(self, word):\n",
    "        if word not in self.map:\n",
    "            return []\n",
    "        return self.map[word].get_list_of_docs()\n",
    "\n",
    "    def create_champion_list(self, size):\n",
    "        for word, posting in self.map.items():\n",
    "            if posting.total_df > size:\n",
    "                self.champion_lists[word] = posting.create_champion_list(size, N)\n",
    "\n",
    "    def give_champion_list(self, word):\n",
    "        if word not in self.champion_lists:\n",
    "            return []\n",
    "        return self.champion_lists[word].get_list_of_docs()\n",
    "\n",
    "    def create_freq_word(self):\n",
    "        for word, posting in self.map.items():\n",
    "            self.freq_with_word.append((posting.total_df, word))\n",
    "\n",
    "    def find_word_with_most_freq_and_del(self):\n",
    "        self.create_freq_word()\n",
    "        self.freq_with_word.sort(reverse=True, key=lambda x: x[0])\n",
    "        most_frequent_words = [word for _, word in self.freq_with_word[:50]]\n",
    "        for word in most_frequent_words:\n",
    "            self.map.pop(word, None)\n",
    "        return most_frequent_words\n",
    "\n",
    "    def __str__(self):\n",
    "        result = \"\"\n",
    "        for word, posting in self.map.items():\n",
    "            result += f\"{word}: {posting}\\n\"\n",
    "            result += \"-----------------------------------------\\n\"\n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کلمه: total_tf=4, total_df=2, word = کلمه\n",
      "doc_tf={1: 3, 2: 1}, positions={1: [2, 4, 5], 2: [7]}\n",
      "-----------------------------------------\n",
      "کلمه2: total_tf=1, total_df=1, word = کلمه2\n",
      "doc_tf={3: 1}, positions={3: [4]}\n",
      "-----------------------------------------\n",
      "\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "posting_list = PostingsList()\n",
    "posting_list.add(\"کلمه\", 1, 2)\n",
    "posting_list.add(\"کلمه\", 1, 4)\n",
    "posting_list.add(\"کلمه\", 1, 5)\n",
    "posting_list.add(\"کلمه\", 2, 7)\n",
    "posting_list.add(\"کلمه2\", 3, 4)\n",
    "\n",
    "posting_list.create_champion_list(size=2)\n",
    "\n",
    "print(posting_list)\n",
    "\n",
    "print(posting_list.get_list_word('کلمه'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
